"""
å¯¹æ¯”åˆ†æè„šæœ¬ï¼šæ°´å¹³åŒå‘ vs æ°´å¹³å•å‘
Compare h_bi (bidirectional) vs h_uni (unidirectional)

è¿è¡Œæ–¹æ³•ï¼š
    python compare_results.py

åŠŸèƒ½ï¼š
1. åŠ è½½ä¸¤ä¸ªå®éªŒçš„è¯„ä¼°ç»“æœ
2. ç”Ÿæˆå¯¹æ¯”å›¾è¡¨
3. è¾“å‡ºè¯¦ç»†çš„ç»Ÿè®¡å¯¹æ¯”
4. ä¿å­˜å¯¹æ¯”æŠ¥å‘Š
"""

import os
import sys
import json
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from pathlib import Path

sys.path.append(os.path.dirname(os.path.abspath(__file__)))


class ResultComparator:
    """ç»“æœå¯¹æ¯”åˆ†æå™¨"""

    def __init__(self):
        """åˆå§‹åŒ–å¯¹æ¯”åˆ†æå™¨"""
        self.results = {}

    def load_results(self, exp_name: str, result_path: str):
        """åŠ è½½å®éªŒç»“æœ"""
        if not os.path.exists(result_path):
            print(f"âš ï¸  æ‰¾ä¸åˆ°ç»“æœæ–‡ä»¶: {result_path}")
            return False

        with open(result_path, 'r') as f:
            self.results[exp_name] = json.load(f)

        print(f"âœ… å·²åŠ è½½: {exp_name} - {result_path}")
        return True

    def print_comparison_table(self):
        """æ‰“å°å¯¹æ¯”è¡¨æ ¼"""
        if len(self.results) < 2:
            print("âŒ éœ€è¦è‡³å°‘ä¸¤ä¸ªå®éªŒç»“æœæ‰èƒ½å¯¹æ¯”")
            return

        print("\n" + "=" * 80)
        print("ğŸ“Š å®éªŒå¯¹æ¯”ç»Ÿè®¡è¡¨")
        print("=" * 80)

        # è·å–æ‰€æœ‰æŒ‡æ ‡
        metrics = ['episode_rewards', 'tasks_completed', 'episode_lengths',
                   'collisions', 'direction_changes']

        # åˆ›å»ºå¯¹æ¯”è¡¨æ ¼
        data = []
        for metric in metrics:
            row = {'Metric': metric.replace('_', ' ').title()}

            for exp_name, result in self.results.items():
                if metric in result['statistics']:
                    stats = result['statistics'][metric]
                    row[f"{exp_name}_mean"] = f"{stats['mean']:.2f}"
                    row[f"{exp_name}_std"] = f"{stats['std']:.2f}"

            data.append(row)

        # æ‰“å°è¡¨æ ¼
        df = pd.DataFrame(data)
        print(df.to_string(index=False))
        print("=" * 80)

        # è®¡ç®—æ”¹è¿›ç™¾åˆ†æ¯”
        if 'h_bi' in self.results and 'h_uni' in self.results:
            print("\nğŸ“ˆ åŒå‘ vs å•å‘ æ”¹è¿›åˆ†æ")
            print("=" * 80)

            bi_tasks = self.results['h_bi']['statistics']['tasks_completed']['mean']
            uni_tasks = self.results['h_uni']['statistics']['tasks_completed']['mean']
            task_improvement = ((bi_tasks - uni_tasks) / uni_tasks * 100) if uni_tasks > 0 else 0

            bi_reward = self.results['h_bi']['statistics']['episode_rewards']['mean']
            uni_reward = self.results['h_uni']['statistics']['episode_rewards']['mean']
            reward_improvement = ((bi_reward - uni_reward) / abs(uni_reward) * 100) if uni_reward != 0 else 0

            bi_collisions = self.results['h_bi']['statistics']['collisions']['mean']
            uni_collisions = self.results['h_uni']['statistics']['collisions']['mean']
            collision_reduction = ((uni_collisions - bi_collisions) / uni_collisions * 100) if uni_collisions > 0 else 0

            print(f"ä»»åŠ¡å®Œæˆæ•°:")
            print(f"  åŒå‘: {bi_tasks:.2f}")
            print(f"  å•å‘: {uni_tasks:.2f}")
            print(f"  æ”¹è¿›: {task_improvement:+.1f}%")

            print(f"\nå¹³å‡å¥–åŠ±:")
            print(f"  åŒå‘: {bi_reward:.2f}")
            print(f"  å•å‘: {uni_reward:.2f}")
            print(f"  æ”¹è¿›: {reward_improvement:+.1f}%")

            print(f"\nç¢°æ’æ¬¡æ•°:")
            print(f"  åŒå‘: {bi_collisions:.2f}")
            print(f"  å•å‘: {uni_collisions:.2f}")
            print(f"  å‡å°‘: {collision_reduction:.1f}%")

            # åŒå‘ç‰¹æœ‰æŒ‡æ ‡
            if 'backward_usage' in self.results['h_bi']['statistics']:
                backward = self.results['h_bi']['statistics']['backward_usage']['mean']
                print(f"\nâœ¨ åŒå‘è·¯ç”±ç‰¹å¾:")
                print(f"  åé€€ä½¿ç”¨ç‡: {backward:.1f}%")
                print(f"  è¯´æ˜: AGVåˆ©ç”¨åé€€åŠŸèƒ½æé«˜çµæ´»æ€§")

            print("=" * 80)

    def plot_comparison(self):
        """ç»˜åˆ¶å¯¹æ¯”å›¾è¡¨"""
        if len(self.results) < 2:
            print("âŒ éœ€è¦è‡³å°‘ä¸¤ä¸ªå®éªŒç»“æœæ‰èƒ½å¯¹æ¯”")
            return

        fig, axes = plt.subplots(2, 3, figsize=(18, 10))
        fig.suptitle('Experimental Comparison: h_bi (Bidirectional) vs h_uni (Unidirectional)',
                     fontsize=16, fontweight='bold')

        metrics = [
            ('episode_rewards', 'Episode Rewards', 0, 0),
            ('tasks_completed', 'Tasks Completed', 0, 1),
            ('episode_lengths', 'Episode Lengths', 0, 2),
            ('collisions', 'Collisions', 1, 0),
            ('direction_changes', 'Direction Changes', 1, 1)
        ]

        colors = {'h_bi': 'blue', 'h_uni': 'orange'}
        labels = {'h_bi': 'Bidirectional', 'h_uni': 'Unidirectional'}

        # ç»˜åˆ¶å¯¹æ¯”å›¾
        for metric, title, row, col in metrics:
            ax = axes[row, col]

            for exp_name, result in self.results.items():
                if metric in result['raw_data']:
                    data = result['raw_data'][metric]
                    ax.plot(data, alpha=0.6, label=labels.get(exp_name, exp_name),
                            color=colors.get(exp_name, 'gray'))
                    ax.axhline(np.mean(data), color=colors.get(exp_name, 'gray'),
                               linestyle='--', alpha=0.8, linewidth=1.5)

            ax.set_xlabel('Episode')
            ax.set_ylabel(title)
            ax.set_title(title)
            ax.legend()
            ax.grid(True, alpha=0.3)

        # ç®±çº¿å›¾å¯¹æ¯”
        ax = axes[1, 2]
        if 'h_bi' in self.results and 'h_uni' in self.results:
            bi_tasks = self.results['h_bi']['raw_data']['tasks_completed']
            uni_tasks = self.results['h_uni']['raw_data']['tasks_completed']

            bp = ax.boxplot([bi_tasks, uni_tasks], labels=['Bidirectional', 'Unidirectional'],
                            patch_artist=True)
            bp['boxes'][0].set_facecolor('lightblue')
            bp['boxes'][1].set_facecolor('lightyellow')

            ax.set_ylabel('Tasks Completed')
            ax.set_title('Task Completion Distribution')
            ax.grid(True, alpha=0.3)

        plt.tight_layout()

        # ä¿å­˜å›¾è¡¨
        save_path = './data/comparison_results.png'
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"\nâœ… å¯¹æ¯”å›¾è¡¨å·²ä¿å­˜: {save_path}")

        plt.show()

    def generate_report(self):
        """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
        if len(self.results) < 2:
            print("âŒ éœ€è¦è‡³å°‘ä¸¤ä¸ªå®éªŒç»“æœæ‰èƒ½ç”ŸæˆæŠ¥å‘Š")
            return

        report = []
        report.append("# å®éªŒå¯¹æ¯”æŠ¥å‘Šï¼šæ°´å¹³åŒå‘ vs æ°´å¹³å•å‘")
        report.append("\n## å®éªŒé…ç½®")

        for exp_name, result in self.results.items():
            report.append(f"\n### {exp_name}")
            report.append(f"- æè¿°: {result.get('description', 'N/A')}")
            if 'config' in result:
                config = result['config']
                report.append(f"- åŒå‘è·¯ç”±: {'å¯ç”¨' if config.get('bidirectional') else 'ç¦ç”¨'}")
                report.append(f"- AGVæ•°é‡: {config.get('num_agents', 'N/A')}")
                report.append(f"- è½¦é“æ•°é‡: {config.get('num_lanes', 'N/A')}")

        report.append("\n## æ€§èƒ½å¯¹æ¯”")
        report.append("\n| æŒ‡æ ‡ | åŒå‘ (h_bi) | å•å‘ (h_uni) | æ”¹è¿› |")
        report.append("|------|-------------|--------------|------|")

        if 'h_bi' in self.results and 'h_uni' in self.results:
            metrics = [
                ('episode_rewards', 'å¹³å‡å¥–åŠ±'),
                ('tasks_completed', 'ä»»åŠ¡å®Œæˆæ•°'),
                ('episode_lengths', 'Episodeé•¿åº¦'),
                ('collisions', 'ç¢°æ’æ¬¡æ•°')
            ]

            for metric_key, metric_name in metrics:
                bi_val = self.results['h_bi']['statistics'][metric_key]['mean']
                uni_val = self.results['h_uni']['statistics'][metric_key]['mean']

                if metric_key == 'collisions':
                    # ç¢°æ’æ¬¡æ•°ï¼šè¶Šå°‘è¶Šå¥½
                    improvement = ((uni_val - bi_val) / uni_val * 100) if uni_val > 0 else 0
                    improvement_str = f"{improvement:.1f}% å‡å°‘"
                else:
                    # å…¶ä»–æŒ‡æ ‡ï¼šè¶Šå¤šè¶Šå¥½
                    improvement = ((bi_val - uni_val) / abs(uni_val) * 100) if uni_val != 0 else 0
                    improvement_str = f"{improvement:+.1f}%"

                report.append(f"| {metric_name} | {bi_val:.2f} | {uni_val:.2f} | {improvement_str} |")

        report.append("\n## ç»“è®º")
        report.append("\nåŸºäºå®éªŒç»“æœï¼ŒåŒå‘è·¯ç”±ç›¸æ¯”å•å‘è·¯ç”±çš„ä¼˜åŠ¿ï¼š")

        if 'h_bi' in self.results and 'h_uni' in self.results:
            bi_tasks = self.results['h_bi']['statistics']['tasks_completed']['mean']
            uni_tasks = self.results['h_uni']['statistics']['tasks_completed']['mean']

            if bi_tasks > uni_tasks:
                report.append("- âœ… ä»»åŠ¡å®Œæˆæ•°æ›´é«˜ï¼Œè¡¨æ˜åŒå‘è·¯ç”±æé«˜äº†è°ƒåº¦æ•ˆç‡")

            if 'backward_usage' in self.results['h_bi']['statistics']:
                backward = self.results['h_bi']['statistics']['backward_usage']['mean']
                report.append(f"- âœ… AGVåˆ©ç”¨åé€€åŠŸèƒ½ï¼ˆä½¿ç”¨ç‡{backward:.1f}%ï¼‰ï¼Œæé«˜çµæ´»æ€§")

            bi_collisions = self.results['h_bi']['statistics']['collisions']['mean']
            uni_collisions = self.results['h_uni']['statistics']['collisions']['mean']

            if bi_collisions < uni_collisions:
                report.append("- âœ… ç¢°æ’æ¬¡æ•°æ›´å°‘ï¼Œåé€€åŠŸèƒ½æœ‰åŠ©äºé¿éšœ")

        report_text = "\n".join(report)

        # ä¿å­˜æŠ¥å‘Š
        report_path = './data/comparison_report.md'
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_text)

        print(f"\nâœ… å¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

        # æ‰“å°æŠ¥å‘Š
        print("\n" + "=" * 80)
        print(report_text)
        print("=" * 80)


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "=" * 80)
    print("ğŸ“Š å®éªŒç»“æœå¯¹æ¯”åˆ†æå·¥å…·")
    print("=" * 80)

    comparator = ResultComparator()

    # åŠ è½½å®éªŒç»“æœ
    results_loaded = 0

    # å°è¯•åŠ è½½æ°´å¹³åŒå‘ç»“æœ
    h_bi_path = './data/logs_h_bi/evaluation_results_h_bi.json'
    if comparator.load_results('h_bi', h_bi_path):
        results_loaded += 1

    # å°è¯•åŠ è½½æ°´å¹³å•å‘ç»“æœ
    h_uni_path = './data/logs_h_uni/evaluation_results_h_uni.json'
    if comparator.load_results('h_uni', h_uni_path):
        results_loaded += 1

    if results_loaded < 2:
        print("\nâŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°è¶³å¤Ÿçš„è¯„ä¼°ç»“æœæ–‡ä»¶")
        print("\nè¯·å…ˆè¿è¡Œè¯„ä¼°è„šæœ¬ï¼š")
        print("  python evaluate_h_bi.py")
        print("  python evaluate_h_uni.py")
        return

    print(f"\nâœ… æˆåŠŸåŠ è½½ {results_loaded} ä¸ªå®éªŒç»“æœ")

    # ç”Ÿæˆå¯¹æ¯”åˆ†æ
    print("\n1ï¸âƒ£  ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼...")
    comparator.print_comparison_table()

    print("\n2ï¸âƒ£  ç”Ÿæˆå¯¹æ¯”å›¾è¡¨...")
    comparator.plot_comparison()

    print("\n3ï¸âƒ£  ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š...")
    comparator.generate_report()

    print("\n" + "=" * 80)
    print("âœ… å¯¹æ¯”åˆ†æå®Œæˆï¼")
    print("=" * 80)
    print("\nç”Ÿæˆçš„æ–‡ä»¶ï¼š")
    print("  - ./data/comparison_results.png  (å¯¹æ¯”å›¾è¡¨)")
    print("  - ./data/comparison_report.md    (å¯¹æ¯”æŠ¥å‘Š)")
    print("=" * 80 + "\n")


if __name__ == "__main__":
    main()